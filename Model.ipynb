{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WC7IdnAg22O-"
      },
      "source": [
        "**Prediction Quesiton**: Were Asian Americans more likely to be attacked in cities/towns with a higher amount of Covid cases due to rise in xenophobia during the Pandemic?\n",
        "\n",
        "**Importance for client**: This research question can guide law enforcement in the future. Even though there may not be the same case of anti-asian hate, there will most likely be more xenophobia in the future. By analyzing this data, we can see if there was actually a rise during the pandemic of attacks on asian americans, and then law enforcement can protect groups in a similar scenario in the future."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Setting Up Data:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "o9dVEza1s06w"
      },
      "outputs": [],
      "source": [
        "# Setting up environment:\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gDD5-jgJvAGK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(13794, 21)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'State', 'Agency', 'Source', 'Solved', 'Year', 'Month',\n",
              "       'Homicide', 'Situation', 'VicAge', 'VicSex', 'VicRace', 'VicEthnic',\n",
              "       'OffAge', 'OffSex', 'OffRace', 'OffEthnic', 'Weapon', 'Relationship',\n",
              "       'VicCount', 'OffCount'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# loading in dataset as dataframe:\n",
        "df = pd.read_csv(\"cleaned_df.csv\")\n",
        "print(df.shape)\n",
        "\n",
        "# previewing the data:\n",
        "df.head(5)\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y24KieKmvC83",
        "outputId": "bcfb2469-b12b-45c0-8262-73464587f5ed"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>State</th>\n",
              "      <th>OffRace</th>\n",
              "      <th>OffAge</th>\n",
              "      <th>Situation</th>\n",
              "      <th>VicRace</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016</td>\n",
              "      <td>January</td>\n",
              "      <td>Alaska</td>\n",
              "      <td>American Indian or Alaskan Native</td>\n",
              "      <td>21.0</td>\n",
              "      <td>Single victim/single offender</td>\n",
              "      <td>American Indian or Alaskan Native</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016</td>\n",
              "      <td>January</td>\n",
              "      <td>Alaska</td>\n",
              "      <td>White</td>\n",
              "      <td>15.0</td>\n",
              "      <td>Multiple victims/single offender</td>\n",
              "      <td>White</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016</td>\n",
              "      <td>January</td>\n",
              "      <td>Alaska</td>\n",
              "      <td>White</td>\n",
              "      <td>15.0</td>\n",
              "      <td>Multiple victims/single offender</td>\n",
              "      <td>White</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2016</td>\n",
              "      <td>January</td>\n",
              "      <td>Alaska</td>\n",
              "      <td>White</td>\n",
              "      <td>34.0</td>\n",
              "      <td>Single victim/multiple offenders</td>\n",
              "      <td>American Indian or Alaskan Native</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2016</td>\n",
              "      <td>January</td>\n",
              "      <td>Alaska</td>\n",
              "      <td>American Indian or Alaskan Native</td>\n",
              "      <td>33.0</td>\n",
              "      <td>Single victim/single offender</td>\n",
              "      <td>American Indian or Alaskan Native</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Year    Month   State                            OffRace  OffAge  \\\n",
              "0  2016  January  Alaska  American Indian or Alaskan Native    21.0   \n",
              "1  2016  January  Alaska                              White    15.0   \n",
              "2  2016  January  Alaska                              White    15.0   \n",
              "3  2016  January  Alaska                              White    34.0   \n",
              "4  2016  January  Alaska  American Indian or Alaskan Native    33.0   \n",
              "\n",
              "                          Situation                            VicRace  \n",
              "0     Single victim/single offender  American Indian or Alaskan Native  \n",
              "1  Multiple victims/single offender                              White  \n",
              "2  Multiple victims/single offender                              White  \n",
              "3  Single victim/multiple offenders  American Indian or Alaskan Native  \n",
              "4     Single victim/single offender  American Indian or Alaskan Native  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# selecting relevant columns to use for model analysis:\n",
        "df_new = df[['Year', 'Month', 'State', 'OffRace', 'OffAge', 'Situation', 'VicRace']]\n",
        "df_new.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Year            0\n",
            "Month           0\n",
            "State           0\n",
            "OffRace      4413\n",
            "OffAge       4441\n",
            "Situation       0\n",
            "VicRace       210\n",
            "dtype: int64\n",
            "   Year    Month   State                            OffRace  OffAge  \\\n",
            "0  2016  January  Alaska  American Indian or Alaskan Native    21.0   \n",
            "1  2016  January  Alaska                              White    15.0   \n",
            "2  2016  January  Alaska                              White    15.0   \n",
            "3  2016  January  Alaska                              White    34.0   \n",
            "4  2016  January  Alaska  American Indian or Alaskan Native    33.0   \n",
            "\n",
            "                          Situation                            VicRace  \n",
            "0     Single victim/single offender  American Indian or Alaskan Native  \n",
            "1  Multiple victims/single offender                              White  \n",
            "2  Multiple victims/single offender                              White  \n",
            "3  Single victim/multiple offenders  American Indian or Alaskan Native  \n",
            "4     Single victim/single offender  American Indian or Alaskan Native  \n",
            "Year         0\n",
            "Month        0\n",
            "State        0\n",
            "OffRace      0\n",
            "OffAge       0\n",
            "Situation    0\n",
            "VicRace      0\n",
            "dtype: int64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/f0/rhgwtvsd01lfbqlqp_ts85wh0000gn/T/ipykernel_45979/3505088697.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_new['OffRace'] = df_new[\"OffRace\"].fillna('Unknown')\n",
            "/var/folders/f0/rhgwtvsd01lfbqlqp_ts85wh0000gn/T/ipykernel_45979/3505088697.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_new['OffAge'] = df_new['OffAge'].fillna(df_new['OffAge'].median())\n",
            "/var/folders/f0/rhgwtvsd01lfbqlqp_ts85wh0000gn/T/ipykernel_45979/3505088697.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_new['VicRace'] = df_new['VicRace'].fillna('Unknown')\n"
          ]
        }
      ],
      "source": [
        "# checking for NaNs:\n",
        "print(df_new.isna().sum())\n",
        "\n",
        "# dropping missing values for 'OffRace' since can not impute for categorical:\n",
        "# df_new = df_new.dropna(subset=['OffRace'], axis=0)\n",
        "df_new['OffRace'] = df_new[\"OffRace\"].fillna('Unknown')\n",
        "\n",
        "\n",
        "# imputing missing values for 'OffAge' with median:\n",
        "df_new['OffAge'] = df_new['OffAge'].fillna(df_new['OffAge'].median())\n",
        "\n",
        "# imputing missing values for 'VicRace' with 'Unknown':\n",
        "df_new['VicRace'] = df_new['VicRace'].fillna('Unknown')\n",
        "\n",
        "# previewing new/cleaned dataframe:\n",
        "print(df_new.head())\n",
        "print(df_new.isna().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**One Hot Encoding Data for Model:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Year', 'OffAge']\n",
            "['Month', 'State', 'OffRace', 'Situation', 'VicRace']\n"
          ]
        }
      ],
      "source": [
        "# separating numerical and categorical columns:\n",
        "\n",
        "# numerical columns:\n",
        "num_cols = df_new.select_dtypes(include=[np.number]).columns.tolist()\n",
        "print(num_cols)\n",
        "\n",
        "# categorical columns:\n",
        "cat_cols = df_new.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "print(cat_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# one-hot encoding categorical columns:\n",
        "df_encoded = pd.get_dummies(df_new, columns=cat_cols, drop_first=True)\n",
        "\n",
        "X = pd.concat([df_new[num_cols], df_encoded], axis=1)\n",
        "y = df_new['VicRace']\n",
        "\n",
        "# splitting data into test/train:\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "could not convert string to float: 'White'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m r2_score\n\u001b[1;32m      7\u001b[0m cart \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mDecisionTreeRegressor(min_samples_leaf\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m cart \u001b[38;5;241m=\u001b[39m cart\u001b[38;5;241m.\u001b[39mfit(X_train, Y_train)\n\u001b[1;32m     10\u001b[0m var_names \u001b[38;5;241m=\u001b[39m cart\u001b[38;5;241m.\u001b[39mfeature_names_in_\n\u001b[1;32m     11\u001b[0m plot_tree(cart, filled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, feature_names\u001b[38;5;241m=\u001b[39mvar_names)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/tree/_classes.py:1404\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m   1377\u001b[0m \n\u001b[1;32m   1378\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1404\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[1;32m   1405\u001b[0m         X,\n\u001b[1;32m   1406\u001b[0m         y,\n\u001b[1;32m   1407\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m   1408\u001b[0m         check_input\u001b[38;5;241m=\u001b[39mcheck_input,\n\u001b[1;32m   1409\u001b[0m     )\n\u001b[1;32m   1410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/tree/_classes.py:318\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(y, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m!=\u001b[39m DOUBLE \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m y\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mcontiguous:\n\u001b[0;32m--> 318\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mascontiguousarray(y, dtype\u001b[38;5;241m=\u001b[39mDOUBLE)\n\u001b[1;32m    320\u001b[0m max_depth \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_leaf, numbers\u001b[38;5;241m.\u001b[39mIntegral):\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'White'"
          ]
        }
      ],
      "source": [
        "# importing all necessary libraries:\n",
        "from sklearn import tree\n",
        "from sklearn.tree import plot_tree\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "cart = tree.DecisionTreeRegressor(min_samples_leaf= 500)\n",
        "cart = cart.fit(X_train, Y_train)\n",
        "\n",
        "var_names = cart.feature_names_in_\n",
        "plot_tree(cart, filled=True, feature_names=var_names)\n",
        "\n",
        "# testing through min_samples_leaf from 1 - 25\n",
        "r2_list = []\n",
        "leaf_values = list(range(1, 26))\n",
        "\n",
        "for leaf in leaf_values:\n",
        "    model = DecisionTreeRegressor(min_samples_leaf=leaf, random_state=42)\n",
        "    model.fit(X_train, Y_train)\n",
        "    y_hat = model.predict(X_test)\n",
        "    r2 = r2_score(Y_test, y_hat)\n",
        "    r2_list.append(r2)\n",
        "\n",
        "best_leaf = leaf_values[r2_list.index(max(r2_list))]\n",
        "best_r2 = max(r2_list)\n",
        "\n",
        "print(f'Best min_sample_left value: {best_leaf} with R^2 of {best_r2:.3f}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
